name: Test Timing Analysis

on:
  workflow_dispatch:
  push:
    branches: [main, fix_cleanup]
  pull_request:
    paths:
      - 'tests/**'
      - 'compute_forecast/**'
      - '.github/workflows/test-timing.yml'

jobs:
  analyze-test-times:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    strategy:
      matrix:
        test-group: ["unit", "integration", "functional", "performance"]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Install uv
      uses: astral-sh/setup-uv@v5
      with:
        enable-cache: true
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: "3.12"
    
    - name: Install dependencies
      run: |
        uv venv
        uv sync --group test
    
    - name: Run tests and collect timing - ${{ matrix.test-group }}
      run: |
        uv run python scripts/analyze_test_times.py tests/${{ matrix.test-group }}
      continue-on-error: true
    
    - name: Upload timing results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-times-${{ matrix.test-group }}
        path: |
          test_times_*.xml
          test_times_*_analysis.json
        retention-days: 30
    
    - name: Generate timing summary
      if: always()
      run: |
        echo "## Test Timing Summary - ${{ matrix.test-group }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Find the latest analysis JSON
        ANALYSIS_FILE=$(ls -t test_times_*_analysis.json | head -1)
        
        if [ -f "$ANALYSIS_FILE" ]; then
          # Extract summary info
          uv run python -c "
import json
with open('$ANALYSIS_FILE') as f:
    data = json.load(f)
    print(f'Total tests: {data[\"total_tests\"]}')
    print(f'Total time: {data[\"total_time\"]:.2f}s')
    print()
    print('Top 10 slowest tests:')
    for i, test in enumerate(data['test_times'][:10]):
        print(f'{i+1}. {test[\"time\"]:.3f}s - {test[\"name\"]}')
          " >> $GITHUB_STEP_SUMMARY
        fi
  
  aggregate-timing:
    needs: analyze-test-times
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Install uv
      uses: astral-sh/setup-uv@v5
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: "3.12"
    
    - name: Download all timing results
      uses: actions/download-artifact@v4
      with:
        path: all-timing-results
    
    - name: Generate consolidated report
      run: |
        echo "# Complete Test Suite Timing Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "Generated on: $(date)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Aggregate all timing data
        uv run python -c "
import json
import glob
from pathlib import Path

all_tests = []
total_time = 0

for json_file in glob.glob('all-timing-results/*/test_times_*_analysis.json'):
    with open(json_file) as f:
        data = json.load(f)
        all_tests.extend(data['test_times'])
        total_time += data['total_time']

# Sort all tests by time
all_tests.sort(key=lambda x: x['time'], reverse=True)

print(f'## Overall Summary')
print(f'- **Total tests**: {len(all_tests)}')
print(f'- **Total time**: {total_time:.2f}s ({total_time/60:.1f} minutes)')
print()
print(f'## Top 20 Slowest Tests Across All Groups')
for i, test in enumerate(all_tests[:20]):
    print(f'{i+1}. **{test[\"time\"]:.3f}s** - {test[\"name\"]}')
        " >> $GITHUB_STEP_SUMMARY