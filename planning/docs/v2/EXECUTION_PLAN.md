# V2 Execution Plan - Paper-Based Requirements Approach

## Overview
**METHODOLOGY PIVOT**: Data-driven preliminary report on 2-year compute needs using paper-based computational requirement extraction as primary methodology, with optional usage pattern validation.

## Week Timeline

### Day 1-2: Paper Analysis Pipeline Development
- **Automated extraction system**: NLP pipeline for computational requirement extraction
- **Paper corpus processing**: Domain categorization, temporal organization
- **Manual validation setup**: Quality control for automated extraction
- **Standardization framework**: Convert to common computational units

### Day 3-4: Computational Requirement Extraction & Comparison
- **Extract external benchmark data**: Hardware specs, duration, scale from academic/industry papers
- **Extract Mila computational data**: Same metrics from Mila papers (2019-2024)
- **Gap analysis**: Compare Mila vs. academic benchmarks vs. industry benchmarks
- **Trend comparison**: Mila growth rates vs. external benchmark evolution
- **Research group mapping**: Assign groups to domains and benchmark targets

### Day 5: Projection & Validation
- **2-year projections**: Domain-specific growth rate application
- **Scale adjustment**: Apply multipliers for "ideal" vs "reported" compute
- **External validation**: Compare with other institutions' paper-based analysis
- **Uncertainty quantification**: Confidence intervals for projections

### Day 6-7: Report Generation
- **Data visualization**: Computational requirements by domain and time
- **Report writing**: 3-4 page preliminary report focused on paper-based projections
- **Resource justification**: Demonstrate research potential with adequate compute

### Optional: Usage Pattern Validation (If Time Permits)
- **Compare projections**: Paper-based vs. usage data validation
- **Identify discrepancies**: Gaps between reported and actual usage
- **Adjustment factors**: Refine projections based on usage comparison

## Technical Implementation

### Paper Analysis Pipeline
- **Text extraction**: NLP for computational statements in papers
- **Hardware normalization**: Convert to standardized GPU-equivalent units
- **Domain classification**: Automatic categorization by research area
- **Temporal analysis**: Growth trends in computational requirements

### Projection Framework
- **Domain-specific growth**: Separate trend analysis per research area
- **Scale multipliers**: Adjust for complete vs. reported computational needs
- **Research group scaling**: Account for group size growth projections
- **Uncertainty modeling**: Bootstrap and scenario-based confidence intervals

### Output Deliverables
1. **Paper-based computational profiles**: Requirements by research domain
2. **Growth projections**: 2-year forecasts with domain breakdown
3. **Resource justification**: Evidence-based case for additional compute
4. **Preliminary report**: Executive summary with key findings

## Success Metrics
- Extract computational data from >60% of relevant papers
- Achieve domain coverage across all major Mila research areas
- Provide <40% uncertainty in domain-specific 2-year projections
- Deliver compelling justification based on research publication evidence

## Next Steps After This Plan
Based on feedback and data quality, determine if deeper analysis is needed or if this preliminary version provides sufficient insights for funding requests.
