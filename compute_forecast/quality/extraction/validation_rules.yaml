# Extraction validation rules configuration

# Completeness requirements by extraction type
completeness_rules:
  gpu_required:
    - gpu_hours
    - gpu_type
  training_required:
    - training_time
    - parameters
  optional:
    - batch_size
    - learning_rate
    - optimizer
    - framework
    - dataset_size
    - epochs

# Field importance weights for completeness scoring
field_importance:
  # Critical fields (0.8-1.0)
  gpu_hours: 1.0
  gpu_type: 0.9
  gpu_count: 0.9
  training_time: 0.9
  parameters: 0.85
  
  # Important fields (0.6-0.8)
  gpu_memory: 0.7
  dataset_size: 0.7
  batch_size: 0.6
  epochs: 0.6
  
  # Optional fields (0.3-0.5)
  framework: 0.5
  cost_estimate: 0.5
  learning_rate: 0.4
  optimizer: 0.4

# Consistency rules and relationships
consistency_rules:
  # GPU hours calculation
  gpu_hours_calculation:
    formula: "gpu_count * training_time"
    tolerance: 0.1  # 10% tolerance
    
  # Parameter-GPU hours scaling
  gpu_hours_vs_parameters:
    relationship: "power"
    exponent: 0.7  # GPU hours ~ parameters^0.7
    tolerance: 0.3  # 30% tolerance
    
  # Temporal scaling
  parameters_vs_year:
    relationship: "exponential"
    growth_rate: 1.5  # 50% annual growth
    tolerance: 0.5  # 50% tolerance
    
  # Model size consistency
  parameters_vs_model_size:
    relationship: "linear"
    factor: 4e-9  # 4 bytes per parameter (float32)
    tolerance: 0.2  # 20% tolerance

# Domain-specific validation ranges
domain_ranges:
  nlp:
    parameters: [1e6, 1e12]
    gpu_hours: [10, 1e6]
    batch_size: [8, 512]
    sequence_length: [128, 4096]
    
  cv:
    parameters: [1e6, 1e10]
    gpu_hours: [10, 1e5]
    batch_size: [16, 1024]
    image_size: [224, 1024]
    
  rl:
    parameters: [1e5, 1e9]
    gpu_hours: [100, 1e6]
    episodes: [1000, 1e8]
    steps_per_episode: [10, 10000]
    
  general:
    parameters: [1e3, 1e13]
    gpu_hours: [0.1, 1e7]
    batch_size: [1, 10000]

# Plausibility ranges for all fields
plausibility_ranges:
  gpu_count:
    min: 1
    max: 10000
    typical: [1, 8, 16, 32, 64, 128, 256, 512]
    
  gpu_memory:
    min: 4
    max: 100
    typical: [8, 11, 16, 24, 32, 40, 48, 80]
    
  training_time:
    min: 0.1  # hours
    max: 8760  # 1 year
    typical_range: [1, 720]  # 1 hour to 1 month
    
  parameters:
    min: 1e3
    max: 1e13
    milestones:
      small: 1e6
      medium: 1e8
      large: 1e9
      xlarge: 1e11
      
  batch_size:
    min: 1
    max: 100000
    typical: [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]
    
  learning_rate:
    min: 1e-8
    max: 1.0
    typical_range: [1e-5, 1e-2]
    
  epochs:
    min: 1
    max: 10000
    typical_range: [10, 300]

# Cross-validation tolerance levels
cross_validation_tolerances:
  # Numeric fields with relative tolerance
  gpu_hours: 0.15      # 15% tolerance
  parameters: 0.10     # 10% tolerance  
  training_time: 0.20  # 20% tolerance
  batch_size: 0.05     # 5% tolerance
  dataset_size: 0.10   # 10% tolerance
  gpu_memory: 0.05     # 5% tolerance
  
  # Exact match required
  gpu_count: 0.0
  gpu_type: 0.0
  epochs: 0.0
  
  # String fields (case-insensitive match)
  framework: "string"
  optimizer: "string"

# Outlier detection thresholds
outlier_thresholds:
  # Field-specific z-score thresholds
  z_score:
    default: 3.0
    gpu_hours: 3.5      # More tolerant
    parameters: 4.0     # Even more tolerant
    batch_size: 2.5     # Stricter
    
  # Field-specific IQR multipliers
  iqr_multiplier:
    default: 1.5
    gpu_hours: 2.0
    parameters: 2.5
    batch_size: 1.5

# Known extreme cases (for contextual validation)
known_extremes:
  parameters:
    gpt3: 175e9
    palm: 540e9
    gpt4: 1.76e12  # Estimated
    bloom: 176e9
    opt175b: 175e9
    
  gpu_hours:
    gpt3: 3.64e6
    palm: 6e6
    bloom: 1.08e6
    
  training_time:
    gpt3: 3550  # hours
    bert: 96    # hours

# Quality thresholds
quality_thresholds:
  high:
    confidence: 0.9
    completeness: 0.85
    agreement: 0.9
    
  medium:
    confidence: 0.7
    completeness: 0.7
    agreement: 0.8
    
  low:
    confidence: 0.5
    completeness: 0.5
    agreement: 0.7
    
  unreliable:
    confidence: 0.0
    completeness: 0.0
    agreement: 0.0